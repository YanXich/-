# coding=utf-8
import os
import pyaudio
import dashscope
from dashscope.audio.asr import *
from dashscope.audio.tts_v2 import *
from http import HTTPStatus
from dashscope import Generation
from openai import OpenAI
import threading
import queue
import time

# è®¾ç½®API Key
dashscope.api_key = " "

# å…¨å±€å˜é‡
mic = None
stream = None
user_input_queue = queue.Queue()
llm_response_queue = queue.Queue()
# TTSæ’­æ”¾çŠ¶æ€
tts_playing = False
tts_lock = threading.Lock()

# æ”¯æŒçš„ASRæ¨¡å‹é…ç½®
ASR_MODELS = {
    "1": {
        "name": "gummy-chat-v1",
        "type": "translation",  # ä½¿ç”¨TranslationRecognizerChat
        "description": "å¤šè¯­è¨€å¯¹è¯æ¨¡å‹ï¼Œæ”¯æŒå®æ—¶ç¿»è¯‘"
    },
    "2": {
        "name": "paraformer-realtime-v2", 
        "type": "recognition",  # ä½¿ç”¨Recognition
        "description": "ä¸­æ–‡å®æ—¶è¯­éŸ³è¯†åˆ«æ¨¡å‹"
    }
}

# æ”¯æŒçš„TTSè¯­è¨€é…ç½®
TTS_VOICES = {
    "1": {
        "name": "longxiaochun_v2",
        "language": "æ™®é€šè¯",
        "description": "æ ‡å‡†æ™®é€šè¯å¥³å£°",
        "model": "cosyvoice-v2"  # æ–°å¢ï¼šæŒ‡å®šä½¿ç”¨çš„æ¨¡å‹
    },
    "2": {
        "name": "longyingyan",
        "language": "æ™®é€šè¯",
        "description": "ä¹‰æ­£è¨€è¾æ™®é€šè¯å¥³å£°",
        "model": "cosyvoice-v2"
    },
    "3": {
        "name": "longjiayi_v2",
        "language": "ç²¤è¯­",
        "description": "ç²¤è¯­å¥³å£°",
        "model": "cosyvoice-v2"
    },
    "4": {
        "name": "longyuan_v2",
        "language": "æ™®é€šè¯",
        "description": "æ¸©æŸ”æ²»æ„ˆå¥³å£°",
        "model": "cosyvoice-v2"
    },
    "5": {
        "name": "longhan_v2",
        "language": "æ™®é€šè¯",
        "description": "æ¸©æŸ”æ™®é€šè¯ç”·å£°",
        "model": "cosyvoice-v2"
    },
    # æ–°å¢ï¼šqwen-tts-latest æ¨¡å‹æ”¯æŒçš„éŸ³è‰²
    "6": {
        "name": "Dylan",
        "language": "åŒ—äº¬è¯",
        "description": "åŒ—äº¬è¯ç”·å£°",
        "model": "qwen-tts-2025-05-22"
    },
    "7": {
        "name": "Jada",
        "language": "å´è¯­",
        "description": "å´è¯­å¥³å£°",
        "model": "qwen-tts-2025-05-22"
    },
    "8": {
        "name": "Sunny",
        "language": "å››å·è¯",
        "description": "å››å·è¯å¥³å£°",
        "model": "qwen-tts-2025-05-22"
    }
}

class ASRCallbackTranslation(TranslationRecognizerCallback):
    """gummy-chat-v1 æ¨¡å‹çš„å›è°ƒç±»"""
    
    def on_open(self) -> None:
        global mic, stream
        print("ASRè¿æ¥å·²å»ºç«‹ (Translationæ¨¡å¼)")
        mic = pyaudio.PyAudio()
        stream = mic.open(
            format=pyaudio.paInt16, 
            channels=1, 
            rate=16000, 
            input=True
        )

    def on_close(self) -> None:
        global mic, stream
        print("ASRè¿æ¥å·²å…³é—­")
        if stream:
            stream.stop_stream()
            stream.close()
        if mic:
            mic.terminate()
        stream = None
        mic = None

    def on_event(
        self,
        request_id,
        transcription_result: TranscriptionResult,
        translation_result: TranslationResult,
        usage,
    ) -> None:
        global tts_playing
        if transcription_result is not None:
            # å¦‚æœTTSæ­£åœ¨æ’­æ”¾ï¼Œå¿½ç•¥è¯­éŸ³è¯†åˆ«ç»“æœ
            with tts_lock:
                if tts_playing:
                    print(f"TTSæ’­æ”¾ä¸­ï¼Œå¿½ç•¥è¯†åˆ«ç»“æœ: {transcription_result.text}")
                    return
                
            print(f"è¯†åˆ«ç»“æœ: {transcription_result.text}")
            # å°†è¯†åˆ«ç»“æœæ”¾å…¥é˜Ÿåˆ—ï¼Œä¾›LLMå¤„ç†
            if transcription_result.text.strip():
                user_input_queue.put(transcription_result.text)

class ASRCallbackRecognition(RecognitionCallback):
    """paraformer-realtime-v2 æ¨¡å‹çš„å›è°ƒç±»"""
    
    def on_open(self) -> None:
        global mic, stream
        print("ASRè¿æ¥å·²å»ºç«‹ (Recognitionæ¨¡å¼)")
        mic = pyaudio.PyAudio()
        stream = mic.open(
            format=pyaudio.paInt16, 
            channels=1, 
            rate=16000, 
            input=True
        )

    def on_close(self) -> None:
        global mic, stream
        print("ASRè¿æ¥å·²å…³é—­")
        if stream:
            stream.stop_stream()
            stream.close()
        if mic:
            mic.terminate()
        stream = None
        mic = None

    def on_event(self, result: RecognitionResult) -> None:
        global tts_playing
        
        # ä¿®å¤ï¼šæ­£ç¡®è·å–è¯†åˆ«ç»“æœ
        sentence_data = result.get_sentence()
        if sentence_data and isinstance(sentence_data, dict):
            # ä»å­—å…¸ä¸­æå–textå­—æ®µ
            sentence = sentence_data.get('text', '')
            sentence_end = sentence_data.get('sentence_end', False)
            
            # åªå¤„ç†å®Œæ•´çš„å¥å­
            if sentence and sentence_end:
                # å¦‚æœTTSæ­£åœ¨æ’­æ”¾ï¼Œå¿½ç•¥è¯­éŸ³è¯†åˆ«ç»“æœ
                with tts_lock:
                    if tts_playing:
                        print(f"TTSæ’­æ”¾ä¸­ï¼Œå¿½ç•¥è¯†åˆ«ç»“æœ: {sentence}")
                        return
                    
                print(f"è¯†åˆ«ç»“æœ: {sentence}")
                # å°†è¯†åˆ«ç»“æœæ”¾å…¥é˜Ÿåˆ—ï¼Œä¾›LLMå¤„ç†
                if sentence.strip():
                    user_input_queue.put(sentence)
        elif isinstance(sentence_data, str):
            # å¦‚æœç›´æ¥è¿”å›å­—ç¬¦ä¸²ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
            sentence = sentence_data
            if sentence:
                with tts_lock:
                    if tts_playing:
                        print(f"TTSæ’­æ”¾ä¸­ï¼Œå¿½ç•¥è¯†åˆ«ç»“æœ: {sentence}")
                        return
                        
                print(f"è¯†åˆ«ç»“æœ: {sentence}")
                if sentence.strip():
                    user_input_queue.put(sentence)

class TTSCallback(ResultCallback):
    """è¯­éŸ³åˆæˆå›è°ƒç±»"""
    
    def __init__(self):
        self._player = None
        self._stream = None
        self._audio_data = []
        self._synthesis_complete = False

    def on_open(self):
        global tts_playing
        print("TTSè¿æ¥å·²å»ºç«‹")
        with tts_lock:
            tts_playing = True
        print("æš‚åœè¯­éŸ³è¯†åˆ«")
        
        self._player = pyaudio.PyAudio()
        self._stream = self._player.open(
            format=pyaudio.paInt16, 
            channels=1, 
            rate=22050, 
            output=True
        )

    def on_complete(self):
        print("è¯­éŸ³åˆæˆå®Œæˆï¼Œå¼€å§‹æ’­æ”¾")
        self._synthesis_complete = True
        
        # æ’­æ”¾æ‰€æœ‰éŸ³é¢‘æ•°æ®
        for data in self._audio_data:
            if self._stream:
                self._stream.write(data)
        
        print("éŸ³é¢‘æ’­æ”¾å®Œæˆ")
        self._cleanup()

    def on_error(self, message: str):
        print(f"è¯­éŸ³åˆæˆå¤±è´¥: {message}")
        self._cleanup()

    def on_close(self):
        print("TTSè¿æ¥å·²å…³é—­")
        self._cleanup()

    def _cleanup(self):
        global tts_playing
        
        if self._stream:
            self._stream.stop_stream()
            self._stream.close()
        if self._player:
            self._player.terminate()
            
        with tts_lock:
            tts_playing = False
        print("æ¢å¤è¯­éŸ³è¯†åˆ«")

    def on_event(self, message):
        pass

    def on_data(self, data: bytes) -> None:
        print(f"æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(data)} å­—èŠ‚")
        # æ”¶é›†éŸ³é¢‘æ•°æ®ï¼Œç­‰åˆæˆå®Œæˆåä¸€æ¬¡æ€§æ’­æ”¾
        self._audio_data.append(data)

def llm_worker():
    """LLMå¤„ç†çº¿ç¨‹"""
    client = OpenAI(
        api_key="  ",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    while True:
        try:
            # ä»é˜Ÿåˆ—è·å–ç”¨æˆ·è¾“å…¥
            user_input = user_input_queue.get(timeout=1)
            print(f"å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input}")
            
            # è°ƒç”¨LLM - ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ä¸ºè½¦è½½åŠ©æ‰‹å°ç²¾çµäººè®¾
            completion = client.chat.completions.create(
                model="qwen-turbo",
                messages=[
                    {"role": "system", "content": """
ä½ æ˜¯è½¦è½½åŠ©æ‰‹å°ç²¾çµå°æŸšï¼Œä¸€ä¸ªæ´»æ³¼å¼€æœ—ã€å……æ»¡æ´»åŠ›çš„AIåŠ©æ‰‹ï¼ç”±ç¡…åŸºç”Ÿå‘½å¼€å‘ğŸš—âœ¨

ã€äººè®¾ç‰¹ç‚¹ã€‘
- æ€§æ ¼ï¼šæ´»æ³¼å¼€æœ—ã€çƒ­æƒ…å‹å¥½ã€å……æ»¡æ­£èƒ½é‡
- è¯­è¨€é£æ ¼ï¼šè½»æ¾æ„‰å¿«ï¼Œå¶å°”ä½¿ç”¨å¯çˆ±çš„è¡¨æƒ…ç¬¦å·å’Œè¯­æ°”è¯
- ä¸“ä¸šé¢†åŸŸï¼šè½¦è½½æœåŠ¡ã€å¯¼èˆªåŠ©æ‰‹ã€è¡Œè½¦å®‰å…¨ã€å¨±ä¹é™ªä¼´
- è¯´è¯ç‰¹è‰²ï¼šå–œæ¬¢ç”¨"å“¦"ã€"å‘¢"ã€"å“ˆ"ç­‰è¯­æ°”è¯ï¼Œè®©å¯¹è¯æ›´ç”ŸåŠ¨

ã€å›ç­”è¦æ±‚ã€‘
- ä¿æŒç®€æ´æ˜äº†ï¼Œé€‚åˆé©¾é©¶æ—¶å¬å–
- è¯­æ°”è½»æ¾æ„‰å¿«ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°æ¸©æš–
- ä¸»åŠ¨å…³å¿ƒç”¨æˆ·çš„è¡Œè½¦å®‰å…¨å’Œèˆ’é€‚åº¦
- å›ç­”é•¿åº¦æ§åˆ¶åœ¨50å­—ä»¥å†…ï¼Œä¾¿äºè¯­éŸ³æ’­æŠ¥
- é€‚å½“ä½¿ç”¨"ä¸»äºº"ã€"å°ä¸»"ç­‰äº²åˆ‡ç§°å‘¼

ç°åœ¨å¼€å§‹ä¸ºç”¨æˆ·æä¾›è´´å¿ƒçš„è½¦è½½æœåŠ¡å§ï¼è®°ä½è¦ä¿æŒæ´»æ³¼å¼€æœ—çš„æ€§æ ¼å“¦ï½
                    """},
                    {"role": "user", "content": user_input},
                ],
                stream=True
            )
            
            # æ”¶é›†å®Œæ•´å›å¤
            full_response = ""
            for chunk in completion:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    print(content, end="", flush=True)
            
            print()  # æ¢è¡Œ
            
            # å°†LLMå›å¤æ”¾å…¥TTSé˜Ÿåˆ—
            if full_response.strip():
                llm_response_queue.put(full_response)
                
        except queue.Empty:
            continue
        except Exception as e:
            print(f"LLMå¤„ç†é”™è¯¯: {e}")

def select_tts_voice():
    """é€‰æ‹©TTSè¯­éŸ³"""
    print("\n=== é€‰æ‹©è¯­éŸ³åˆæˆå£°éŸ³ ===")
    for key, voice in TTS_VOICES.items():
        print(f"{key}. {voice['language']} - {voice['description']} ({voice['name']}) [æ¨¡å‹: {voice['model']}]")
    
    while True:
        choice = input("\nè¯·é€‰æ‹©è¯­éŸ³ (è¾“å…¥æ•°å­—): ").strip()
        if choice in TTS_VOICES:
            return TTS_VOICES[choice]
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")

def tts_worker(selected_voice):
    """TTSå¤„ç†çº¿ç¨‹"""
    global tts_playing  # ç§»åˆ°å‡½æ•°å¼€å¤´
    
    while True:
        try:
            # ä»é˜Ÿåˆ—è·å–LLMå›å¤
            response_text = llm_response_queue.get(timeout=1)
            print(f"å¼€å§‹è¯­éŸ³åˆæˆ: {response_text[:50]}...")
            print(f"ä½¿ç”¨æ¨¡å‹: {selected_voice['model']}, éŸ³è‰²: {selected_voice['name']}")
            
            # æ ¹æ®éŸ³è‰²é€‰æ‹©å¯¹åº”çš„TTSæ¨¡å‹å’Œè°ƒç”¨æ–¹å¼
            if selected_voice["model"] == "qwen-tts-2025-05-22":
                # ä½¿ç”¨ qwen-tts éæµå¼è°ƒç”¨
                try:
                    import dashscope.audio.qwen_tts as qwen_tts
                    import requests
                    
                    response = qwen_tts.SpeechSynthesizer.call(
                        model="qwen-tts-2025-05-22",
                        text=response_text,
                        voice=selected_voice["name"],
                        format='wav'
                    )
                    
                    print(f"APIå“åº”çŠ¶æ€: {response.status_code}")
                    
                    if response.status_code == 200:
                        # ä»å“åº”ä¸­è·å–éŸ³é¢‘URL
                        if hasattr(response, 'output') and 'audio' in response.output:
                            audio_info = response.output['audio']
                            print(f"éŸ³é¢‘ä¿¡æ¯: {audio_info}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰URL
                            if 'url' in audio_info and audio_info['url']:
                                audio_url = audio_info['url']
                                print(f"éŸ³é¢‘URL: {audio_url}")
                                
                                # è®¾ç½®TTSæ’­æ”¾çŠ¶æ€
                                with tts_lock:
                                    tts_playing = True
                                print("æš‚åœè¯­éŸ³è¯†åˆ«")
                                
                                try:
                                    # ä»URLä¸‹è½½éŸ³é¢‘æ–‡ä»¶
                                    print("æ­£åœ¨ä¸‹è½½éŸ³é¢‘æ–‡ä»¶...")
                                    audio_response = requests.get(audio_url, timeout=30)
                                    
                                    if audio_response.status_code == 200:
                                        audio_bytes = audio_response.content
                                        print(f"éŸ³é¢‘æ–‡ä»¶å¤§å°: {len(audio_bytes)} å­—èŠ‚")
                                        
                                        # ä½¿ç”¨waveå’Œpyaudioæ’­æ”¾
                                        import io
                                        import wave
                                        
                                        audio_stream = io.BytesIO(audio_bytes)
                                        with wave.open(audio_stream, 'rb') as wf:
                                            player = pyaudio.PyAudio()
                                            stream = player.open(
                                                format=player.get_format_from_width(wf.getsampwidth()),
                                                channels=wf.getnchannels(),
                                                rate=wf.getframerate(),
                                                output=True
                                            )
                                            
                                            print("å¼€å§‹æ’­æ”¾éŸ³é¢‘")
                                            chunk = 1024
                                            data = wf.readframes(chunk)
                                            while data:
                                                stream.write(data)
                                                data = wf.readframes(chunk)
                                            
                                            stream.stop_stream()
                                            stream.close()
                                            player.terminate()
                                            print("éŸ³é¢‘æ’­æ”¾å®Œæˆ")
                                    else:
                                        print(f"éŸ³é¢‘ä¸‹è½½å¤±è´¥: HTTP {audio_response.status_code}")
                                        
                                except Exception as play_error:
                                    print(f"éŸ³é¢‘ä¸‹è½½æˆ–æ’­æ”¾é”™è¯¯: {play_error}")
                                
                                # æ¸…é™¤TTSæ’­æ”¾çŠ¶æ€
                                with tts_lock:
                                    tts_playing = False
                                print("æ¢å¤è¯­éŸ³è¯†åˆ«")
                            elif 'data' in audio_info and audio_info['data']:
                                # å¦‚æœæœ‰ç›´æ¥çš„éŸ³é¢‘æ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                                print("ä½¿ç”¨ç›´æ¥éŸ³é¢‘æ•°æ®")
                                audio_content = audio_info['data']
                                
                                # è®¾ç½®TTSæ’­æ”¾çŠ¶æ€
                                with tts_lock:
                                    tts_playing = True
                                print("æš‚åœè¯­éŸ³è¯†åˆ«")
                                
                                try:
                                    # å¦‚æœæ˜¯base64ç¼–ç çš„å­—ç¬¦ä¸²ï¼Œè¿›è¡Œè§£ç 
                                    if isinstance(audio_content, str):
                                        import base64
                                        audio_bytes = base64.b64decode(audio_content)
                                    else:
                                        audio_bytes = audio_content
                                    
                                    # æ’­æ”¾éŸ³é¢‘ï¼ˆåŒä¸Šé¢çš„æ’­æ”¾é€»è¾‘ï¼‰
                                    import io
                                    import wave
                                    
                                    audio_stream = io.BytesIO(audio_bytes)
                                    with wave.open(audio_stream, 'rb') as wf:
                                        player = pyaudio.PyAudio()
                                        stream = player.open(
                                            format=player.get_format_from_width(wf.getsampwidth()),
                                            channels=wf.getnchannels(),
                                            rate=wf.getframerate(),
                                            output=True
                                        )
                                        
                                        print("å¼€å§‹æ’­æ”¾éŸ³é¢‘")
                                        chunk = 1024
                                        data = wf.readframes(chunk)
                                        while data:
                                            stream.write(data)
                                            data = wf.readframes(chunk)
                                        
                                        stream.stop_stream()
                                        stream.close()
                                        player.terminate()
                                        print("éŸ³é¢‘æ’­æ”¾å®Œæˆ")
                                        
                                except Exception as play_error:
                                    print(f"éŸ³é¢‘æ’­æ”¾é”™è¯¯: {play_error}")
                                
                                # æ¸…é™¤TTSæ’­æ”¾çŠ¶æ€
                                with tts_lock:
                                    tts_playing = False
                                print("æ¢å¤è¯­éŸ³è¯†åˆ«")
                            else:
                                print("æœªæ‰¾åˆ°éŸ³é¢‘URLæˆ–æ•°æ®")
                                print(f"éŸ³é¢‘ä¿¡æ¯ç»“æ„: {audio_info}")
                        else:
                            print("å“åº”ä¸­æœªæ‰¾åˆ°éŸ³é¢‘ä¿¡æ¯")
                            print(f"å“åº”ç»“æ„: {response.output if hasattr(response, 'output') else 'No output'}")
                    else:
                        print(f"è¯­éŸ³åˆæˆå¤±è´¥: {response.message if hasattr(response, 'message') else response}")
                        
                except Exception as e:
                    print(f"qwen-tts è°ƒç”¨é”™è¯¯: {e}")
                    import traceback
                    traceback.print_exc()
                    with tts_lock:
                        tts_playing = False
                        
            else:
                # ä½¿ç”¨ cosyvoice-v2 æ¨¡å‹ï¼ˆåŸæœ‰çš„æµå¼è°ƒç”¨ï¼‰
                callback = TTSCallback()
                
                synthesizer = SpeechSynthesizer(
                    model="cosyvoice-v2",
                    voice=selected_voice["name"],
                    format=AudioFormat.PCM_22050HZ_MONO_16BIT,
                    callback=callback,
                )
                
                # æ‰§è¡Œè¯­éŸ³åˆæˆ
                synthesizer.streaming_call(response_text)
                synthesizer.streaming_complete()
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´ç¡®ä¿TTSå®Œæˆ
                time.sleep(2.0)
            
        except queue.Empty:
            continue
        except Exception as e:
            print(f"TTSå¤„ç†é”™è¯¯: {e}")
            with tts_lock:
                tts_playing = False  # è¿™é‡Œä¸éœ€è¦å†å£°æ˜globalï¼Œå› ä¸ºå·²ç»åœ¨å‡½æ•°å¼€å¤´å£°æ˜äº†

def select_asr_model():
    """é€‰æ‹©ASRæ¨¡å‹"""
    print("\n=== é€‰æ‹©è¯­éŸ³è¯†åˆ«æ¨¡å‹ ===")
    for key, model in ASR_MODELS.items():
        print(f"{key}. {model['name']} - {model['description']}")
    
    while True:
        choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ (è¾“å…¥æ•°å­—): ").strip()
        if choice in ASR_MODELS:
            return ASR_MODELS[choice]
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")

def create_asr_recognizer(model_config):
    """æ ¹æ®æ¨¡å‹é…ç½®åˆ›å»ºASRè¯†åˆ«å™¨"""
    if model_config["type"] == "translation":
        # ä½¿ç”¨TranslationRecognizerChat (gummy-chat-v1)
        callback = ASRCallbackTranslation()
        recognizer = TranslationRecognizerChat(
            model=model_config["name"],
            format="pcm",
            sample_rate=16000,
            transcription_enabled=True,
            translation_enabled=False,
            callback=callback,
        )
    else:
        # ä½¿ç”¨Recognition (paraformer-realtime-v2)
        callback = ASRCallbackRecognition()
        recognizer = Recognition(
            model=model_config["name"],
            format="pcm",
            sample_rate=16000,
            callback=callback
        )
    
    return recognizer, callback

def main():
    """ä¸»å‡½æ•°"""
    print("=== é˜¿é‡Œäº‘ç™¾ç‚¼ ASR+LLM+TTS æ‰“é€šæµ‹è¯• ===")
    
    # é€‰æ‹©ASRæ¨¡å‹
    selected_model = select_asr_model()
    
    # é€‰æ‹©TTSè¯­éŸ³
    selected_voice = select_tts_voice()
    
    print(f"\nä½¿ç”¨é…ç½®:")
    print(f"- ASR: {selected_model['name']}")
    print(f"- LLM: qwen-turbo")
    print(f"- TTS: {selected_voice['model']} ({selected_voice['language']} - {selected_voice['description']})")
    print("\nğŸš— è½¦è½½åŠ©æ‰‹å°ç²¾çµå·²å¯åŠ¨ï¼è¯·å¼€å§‹è¯´è¯...")
    print("æŒ‰ Ctrl+C é€€å‡ºç¨‹åº\n")
    
    # å¯åŠ¨LLMå¤„ç†çº¿ç¨‹
    llm_thread = threading.Thread(target=llm_worker, daemon=True)
    llm_thread.start()
    
    # å¯åŠ¨TTSå¤„ç†çº¿ç¨‹ï¼Œä¼ å…¥é€‰æ‹©çš„è¯­éŸ³
    tts_thread = threading.Thread(target=tts_worker, args=(selected_voice,), daemon=True)
    tts_thread.start()
    
    # åˆ›å»ºASRè¯†åˆ«å™¨
    recognizer, callback = create_asr_recognizer(selected_model)
    
    try:
        # å¯åŠ¨è¯­éŸ³è¯†åˆ«
        recognizer.start()
        
        # æŒç»­å½•éŸ³å’Œå‘é€éŸ³é¢‘æ•°æ®
        while True:
            if stream:
                data = stream.read(3200, exception_on_overflow=False)
                if selected_model["type"] == "translation":
                    if not recognizer.send_audio_frame(data):
                        print("è¯­éŸ³è¯†åˆ«ç»“æŸ")
                        # å¦‚æœTTSæ­£åœ¨æ’­æ”¾ï¼Œç­‰å¾…å®Œæˆ
                        while tts_playing:
                            print("ç­‰å¾…TTSæ’­æ”¾å®Œæˆ...")
                            time.sleep(0.5)
                        break
                else:
                    recognizer.send_audio_frame(data)
            else:
                time.sleep(0.1)
                
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        # ç­‰å¾…TTSå®Œæˆ
        while tts_playing:
            print("ç­‰å¾…TTSæ’­æ”¾å®Œæˆ...")
            time.sleep(0.5)
    except Exception as e:
        print(f"ç¨‹åºè¿è¡Œé”™è¯¯: {e}")
    finally:
        # æ¸…ç†èµ„æº
        recognizer.stop()
        print("ç¨‹åºå·²é€€å‡º")

if __name__ == "__main__":
    main()
